{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wegner Ising Gauge Theory (WIGT): Sampling, RG Learning, and String Tension\n",
    "\n",
    "**Model.** Spins live on links: $\\sigma_\\ell \\in \\{\\pm 1\\}$. The Hamiltonian is the plaquette term\n",
    "$$\n",
    "H(\\sigma) \\;=\\; -K \\sum_{\\square} \\prod_{\\ell \\in \\square} \\sigma_\\ell,\n",
    "$$\n",
    "with coupling $K$.\n",
    "\n",
    "**Wilson loop.** For a closed contour $C$, define\n",
    "$$\n",
    "W(C)=\\prod_{\\ell\\in C}\\sigma_\\ell.\n",
    "$$\n",
    "In a confining phase, $\\langle W(C)\\rangle \\sim e^{-\\sigma A(C)}$ (area law), where $\\sigma$ is the **string tension**. In a deconfined phase, perimeter-law behavior dominates.\n",
    "\n",
    "**Notebook goals.**\n",
    "1. Implement sampling (Metropolis, Cluster) and basic diagnostics (histograms, ACF, ESS).\n",
    "2. Learn $K$ from samples via RISE / pseudo-likelihood / ML approximations.\n",
    "3. Perform multiple RG blocking schemes and estimate the flowed $K$.\n",
    "4. Compute Wilson loops and extract the string tension $\\sigma$ from area-law decay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Lattice construction & utilities\n",
    "\n",
    "We index **horizontal** (`hmap`) and **vertical** (`vmap`) links separately on an $n\\times n$ periodic lattice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Random\n",
    "using Statistics\n",
    "using StatsBase\n",
    "using StatsPlots\n",
    "using DataFrames\n",
    "using Printf\n",
    "using JuMP\n",
    "using Ipopt\n",
    "using MathOptInterface\n",
    "\n",
    "# ---------- Lattice: link indices & plaquettes ----------\n",
    "\n",
    "function link_indices(n::Int)\n",
    "    hmap = Dict{Tuple{Int, Int}, Int}()\n",
    "    vmap = Dict{Tuple{Int, Int}, Int}()\n",
    "    idx = 1\n",
    "    for i in 1:n, j in 1:n\n",
    "        hmap[(i,j)] = idx; idx += 1\n",
    "    end\n",
    "    for i in 1:n, j in 1:n\n",
    "        vmap[(i,j)] = idx; idx += 1\n",
    "    end\n",
    "    return (hmap, vmap)\n",
    "end\n",
    "\n",
    "function plaquettes(n::Int, hmap::Dict{Tuple{Int, Int}, Int}, vmap::Dict{Tuple{Int, Int}, Int})\n",
    "    plaqs = Vector{NTuple{4, Int}}()\n",
    "    for i in 1:n, j in 1:n\n",
    "        top    = hmap[(i, j)]\n",
    "        right  = vmap[(i, mod1(j+1, n))]\n",
    "        bottom = hmap[(mod1(i+1, n), j)]\n",
    "        left   = vmap[(i, j)]\n",
    "        push!(plaqs, (top, right, bottom, left))\n",
    "    end\n",
    "    return plaqs\n",
    "end\n",
    "\n",
    "# ---------- Observables & diagnostics ----------\n",
    "\n",
    "function average_plaquette_energy(samples::Matrix{Float64}, plaqlist::Vector{NTuple{4, Int}})\n",
    "    total = 0.0\n",
    "    num_conf, _ = size(samples)\n",
    "    for p in plaqlist\n",
    "        total += sum(samples[:, p[1]] .* samples[:, p[2]] .* samples[:, p[3]] .* samples[:, p[4]])\n",
    "    end\n",
    "    return total / (num_conf * length(plaqlist))\n",
    "end\n",
    "\n",
    "function compute_plaquette_energy_per_sample(samples::Matrix{Float64}, plaqlist::Vector{NTuple{4, Int}})\n",
    "    num_conf, _ = size(samples)\n",
    "    num_plaq = length(plaqlist)\n",
    "    energies = zeros(Float64, num_conf)\n",
    "    for p in plaqlist\n",
    "        energies .+= samples[:, p[1]] .* samples[:, p[2]] .* samples[:, p[3]] .* samples[:, p[4]]\n",
    "    end\n",
    "    energies ./= num_plaq\n",
    "    return energies\n",
    "end\n",
    "\n",
    "function compute_and_plot_acf(observable::Vector{Float64}; max_lag::Int=1000)\n",
    "    acf_full = autocor(observable)\n",
    "    acf_vals = acf_full[2:min(1+max_lag, length(acf_full))]\n",
    "    plot(1:length(acf_vals), acf_vals, title=\"Autocorrelation Function\", xlabel=\"Lag\", ylabel=\"ACF\", legend=false)\n",
    "    return acf_vals\n",
    "end\n",
    "\n",
    "function estimate_autocorrelation_length(acf::Vector{Float64}; cutoff::Float64=0.05)\n",
    "    valid_lags = findall(x -> abs(x) > cutoff, acf)\n",
    "    if isempty(valid_lags); return 0.0; end\n",
    "    last_valid = last(valid_lags)\n",
    "    tau = 1.0 + 2.0 * sum(acf[1:last_valid])\n",
    "    return tau\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sampling algorithms (**Metropolis** and **Cluster**)\n",
    "\n",
    "We keep both for comparison. Other samplers (heat bath, PT, overrelaxation) can be added analogously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function metropolis_matrix(n::Int, plaqlist::Vector{NTuple{4, Int}},\n",
    "                           K::Float64, nsteps::Int, nburn::Int, samples_matrix::Matrix{Float64};\n",
    "                           step_interval::Int = n*n)\n",
    "    num_samples = size(samples_matrix, 1)\n",
    "    total_possible = floor(Int, (nsteps - nburn) / step_interval)\n",
    "    if total_possible < num_samples\n",
    "        @warn \"Preallocated slots = $num_samples, collectable = $total_possible.\"\n",
    "        num_samples = total_possible\n",
    "    end\n",
    "\n",
    "    nvars = 2n*n\n",
    "    config = ones(Float64, nvars)\n",
    "\n",
    "    link_plaquettes = [Int[] for _ in 1:nvars]\n",
    "    for (pi, p) in enumerate(plaqlist)\n",
    "        for l in p\n",
    "            push!(link_plaquettes[l], pi)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    function energy_delta_for_flip(l)\n",
    "        ΔEplaq = 0.0\n",
    "        for pi in link_plaquettes[l]\n",
    "            p = plaqlist[pi]\n",
    "            prod_now = config[p[1]] * config[p[2]] * config[p[3]] * config[p[4]]\n",
    "            ΔEplaq += (-prod_now) - prod_now\n",
    "        end\n",
    "        return -K * ΔEplaq\n",
    "    end\n",
    "\n",
    "    sample_idx = 1\n",
    "    for sweep in 1:nsteps\n",
    "        for l in randperm(nvars)\n",
    "            dE = energy_delta_for_flip(l)\n",
    "            if dE <= 0 || rand() < exp(-dE)\n",
    "                config[l] *= -1\n",
    "            end\n",
    "        end\n",
    "        if sweep > nburn && (sweep - nburn) % step_interval == 0\n",
    "            if sample_idx <= size(samples_matrix,1)\n",
    "                samples_matrix[sample_idx, :] = config\n",
    "                sample_idx += 1\n",
    "            else\n",
    "                break\n",
    "            end\n",
    "        end\n",
    "        if sweep % 50_000 == 0\n",
    "            @printf(\"Metropolis: sweep %d / %d\\n\", sweep, nsteps)\n",
    "        end\n",
    "    end\n",
    "    return samples_matrix\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function cluster_sampler(n::Int, plaqlist::Vector{NTuple{4, Int}},\n",
    "                         K::Float64, nsteps::Int, nburn::Int,\n",
    "                         samples_matrix::Matrix{Float64};\n",
    "                         step_interval::Int=1)\n",
    "\n",
    "    num_samples = size(samples_matrix, 1)\n",
    "    nvars = 2n*n\n",
    "    config = ones(Float64, nvars)\n",
    "\n",
    "    # adjacency via shared plaquettes\n",
    "    link_neighbors = [Set{Int}() for _ in 1:nvars]\n",
    "    for p in plaqlist\n",
    "        for i in 1:4, j in (i+1):4\n",
    "            push!(link_neighbors[p[i]], p[j])\n",
    "            push!(link_neighbors[p[j]], p[i])\n",
    "        end\n",
    "    end\n",
    "\n",
    "    sample_idx = 1\n",
    "    for sweep in 1:nsteps\n",
    "        visited = falses(nvars)\n",
    "        clusters = Vector{Vector{Int}}()\n",
    "        for start in 1:nvars\n",
    "            if visited[start]; continue; end\n",
    "            cl = Int[]\n",
    "            queue = [start]\n",
    "            visited[start] = true\n",
    "            while !isempty(queue)\n",
    "                l = popfirst!(queue)\n",
    "                push!(cl, l)\n",
    "                for nb in link_neighbors[l]\n",
    "                    if !visited[nb] && config[nb] == config[l]\n",
    "                        p_bond = 1.0 - exp(-2K)\n",
    "                        if rand() < p_bond\n",
    "                            visited[nb] = true\n",
    "                            push!(queue, nb)\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "            push!(clusters, cl)\n",
    "        end\n",
    "        for cl in clusters\n",
    "            if rand() < 0.5\n",
    "                for l in cl; config[l] *= -1; end\n",
    "            end\n",
    "        end\n",
    "\n",
    "        if sweep > nburn && (sweep - nburn) % step_interval == 0\n",
    "            if sample_idx <= num_samples\n",
    "                samples_matrix[sample_idx, :] = config\n",
    "                sample_idx += 1\n",
    "            else\n",
    "                break\n",
    "            end\n",
    "        end\n",
    "        if sweep % 10_000 == 0\n",
    "            @printf(\"Cluster: sweep %d / %d\\n\", sweep, nsteps)\n",
    "        end\n",
    "    end\n",
    "    return samples_matrix\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Learning the coupling \\(K\\)\n",
    "\n",
    "We provide multiple estimators: **RISE**, normalized RISE (stabilized), **pseudo-likelihood**, and a simple **ML** surrogate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Base.Threads\n",
    "const MOI = MathOptInterface\n",
    "\n",
    "function multiRISE_links_only_direct(samples::Matrix{Float64},\n",
    "                                     plaqlist::Vector{NTuple{4, Int}};\n",
    "                                     lambda::Float64=0.0)\n",
    "    num_conf, _ = size(samples)\n",
    "    s = zeros(Float64, num_conf)\n",
    "    @inbounds for p in plaqlist\n",
    "        s .+= samples[:, p[1]] .* samples[:, p[2]] .* samples[:, p[3]] .* samples[:, p[4]]\n",
    "    end\n",
    "\n",
    "    model = Model(Ipopt.Optimizer)\n",
    "    set_optimizer_attribute(model, \"print_level\", 0)\n",
    "    @variable(model, x >= 0.0)\n",
    "    @NLobjective(model, Min, (1/num_conf)*sum(exp.(-x * s[k]) for k in 1:num_conf) + lambda * x)\n",
    "    optimize!(model)\n",
    "    return value(x)\n",
    "end\n",
    "\n",
    "function multiRISE_normalized(samples::Matrix{Float64},\n",
    "                              plaqlist::Vector{NTuple{4,Int}}; λ::Float64=0.0)\n",
    "    N, _ = size(samples)\n",
    "    P = length(plaqlist)\n",
    "    s = zeros(Float64, N)\n",
    "    @inbounds for (t,r,b,l) in plaqlist\n",
    "        s .+= samples[:,t] .* samples[:,r] .* samples[:,b] .* samples[:,l]\n",
    "    end\n",
    "    s ./= P\n",
    "    model = Model(Ipopt.Optimizer)\n",
    "    set_optimizer_attribute(model, \"print_level\", 0)\n",
    "    @variable(model, x >= 0.0)\n",
    "    @NLobjective(model, Min, (1/N)*sum(exp(-x * s[k]) for k in 1:N) + λ*x^2)\n",
    "    optimize!(model)\n",
    "    return value(x)\n",
    "end\n",
    "\n",
    "function PL_links(samples::Matrix{Float64}, plaqlist::Vector{NTuple{4, Int}}; lambda::Float64=0.0)\n",
    "    num_conf, _ = size(samples)\n",
    "    s = zeros(Float64, num_conf)\n",
    "    @inbounds for p in plaqlist\n",
    "        s .+= samples[:, p[1]] .* samples[:, p[2]] .* samples[:, p[3]] .* samples[:, p[4]]\n",
    "    end\n",
    "    model = Model(Ipopt.Optimizer)\n",
    "    set_optimizer_attribute(model, \"print_level\", 0)\n",
    "    @variable(model, x)\n",
    "    @constraint(model, x >= 0)\n",
    "    @NLobjective(model, Min, (1/num_conf)*sum(log(1 + exp.(-2 * x * s[k])) for k in 1:num_conf))\n",
    "    optimize!(model)\n",
    "    return value(x)\n",
    "end\n",
    "\n",
    "function robust_RISE_estimator(samples::Matrix{Float64}, plaqlist::Vector{NTuple{4, Int}}; verbose::Bool=true)\n",
    "    num_conf, _ = size(samples)\n",
    "    P = length(plaqlist)\n",
    "    s = zeros(Float64, num_conf)\n",
    "    @inbounds for (t,r,b,l) in plaqlist\n",
    "        s .+= samples[:,t] .* samples[:,r] .* samples[:,b] .* samples[:,l]\n",
    "    end\n",
    "    s ./= P\n",
    "    best_K, best_obj = 0.0, Inf\n",
    "    for init_K in (0.1, 0.5, 1.0, 2.0, 3.0)\n",
    "        model = Model(Ipopt.Optimizer)\n",
    "        set_optimizer_attribute(model, \"print_level\", 0)\n",
    "        set_optimizer_attribute(model, \"max_iter\", 1000)\n",
    "        @variable(model, 0.001 <= x <= 10.0, start=init_K)\n",
    "        @NLobjective(model, Min, (1/num_conf)*sum(exp(-x * s[k]) for k in 1:num_conf) + 1e-4*x^2)\n",
    "        optimize!(model)\n",
    "        if termination_status(model) in (MOI.OPTIMAL, MOI.LOCALLY_SOLVED)\n",
    "            obj = objective_value(model)\n",
    "            if obj < best_obj\n",
    "                best_obj, best_K = obj, value(x)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    verbose && println(\"Best RISE K = \", best_K)\n",
    "    return best_K\n",
    "end\n",
    "\n",
    "function ML_estimator_plaquette(samples::Matrix{Float64}, plaqlist::Vector{NTuple{4, Int}}; verbose::Bool=true)\n",
    "    avg_plaq = 0.0\n",
    "    for p in plaqlist\n",
    "        avg_plaq += mean(samples[:, p[1]] .* samples[:, p[2]] .* samples[:, p[3]] .* samples[:, p[4]])\n",
    "    end\n",
    "    avg_plaq /= length(plaqlist)\n",
    "    model = Model(Ipopt.Optimizer)\n",
    "    set_optimizer_attribute(model, \"print_level\", 0)\n",
    "    @variable(model, 0.001 <= K_est <= 5.0, start=1.0)\n",
    "    @NLobjective(model, Min, (avg_plaq - tanh(K_est))^2)\n",
    "    optimize!(model)\n",
    "    K_ml = value(K_est)\n",
    "    if avg_plaq > 0.9\n",
    "        K_ref = atanh(avg_plaq) * 1.1\n",
    "        verbose && println(\"ML basic K = $K_ml, refined = $K_ref\")\n",
    "        return K_ref\n",
    "    end\n",
    "    return K_ml\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. RG coarse-graining schemes\n",
    "\n",
    "We include multiple blocking maps (overlapping, majority, 4×4, decimation, checkerboards) and RG drivers that estimate flowed \\(K\\) via RISE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function coarse_plaquettes_4x4(samples_matrix::Matrix{Float64}, (h,v), n::Int)\n",
    "    new_n = div(n,2)\n",
    "    sizeN = size(samples_matrix,1)\n",
    "    s_new = Matrix{Float64}(undef, sizeN, 2*new_n*new_n)\n",
    "    (h_new,v_new) = link_indices(new_n)\n",
    "    new_plaqs = plaquettes(new_n, h_new, v_new)\n",
    "    for k in 0:2:new_n-1, l in 0:2:new_n-1\n",
    "        s_new[:, h_new[mod1(k+1,new_n), mod1(l+1,new_n)]] =\n",
    "            samples_matrix[:, h[mod1(4k+1,n), mod1(4l+1,n)]] .* samples_matrix[:, h[mod1(4k+1,n), mod1(4l+2,n)]] .* samples_matrix[:, h[mod1(4k+1,n), mod1(4l+3,n)]]\n",
    "        s_new[:, h_new[mod1(k+2,new_n), mod1(l+1,new_n)]] =\n",
    "            samples_matrix[:, h[mod1(4k+4,n), mod1(4l+1,n)]] .* samples_matrix[:, h[mod1(4k+4,n), mod1(4l+2,n)]] .* samples_matrix[:, h[mod1(4k+4,n), mod1(4l+3,n)]]\n",
    "        s_new[:, v_new[mod1(k+1,new_n), mod1(l+1,new_n)]] =\n",
    "            samples_matrix[:, v[mod1(4k+1,n), mod1(4l+1,n)]] .* samples_matrix[:, v[mod1(4k+2,n), mod1(4l+1,n)]] .* samples_matrix[:, v[mod1(4k+3,n), mod1(4l+1,n)]]\n",
    "        s_new[:, v_new[mod1(k+1,new_n), mod1(l+2,new_n)]] =\n",
    "            samples_matrix[:, v[mod1(4k+1,n), mod1(4l+4,n)]] .* samples_matrix[:, v[mod1(4k+2,n), mod1(4l+4,n)]] .* samples_matrix[:, v[mod1(4k+3,n), mod1(4l+4,n)]]\n",
    "        s_new[:, h_new[mod1(k+1,new_n), mod1(l+2,new_n)]] =\n",
    "            samples_matrix[:, h[mod1(4k+1,n), mod1(4l+4,n)]] .* samples_matrix[:, v[mod1(4k+2,n), mod1(4l+4,n)]]\n",
    "        s_new[:, h_new[mod1(k+2,new_n), mod1(l+2,new_n)]] =\n",
    "            samples_matrix[:, h[mod1(4k+3,n), mod1(4l+4,n)]] .* samples_matrix[:, h[mod1(4k+4,n), mod1(4l+4,n)]]\n",
    "        s_new[:, v_new[mod1(k+2,new_n), mod1(l+1,new_n)]] =\n",
    "            samples_matrix[:, v[mod1(4k+4,n), mod1(4l+1,n)]] .* samples_matrix[:, v[mod1(4k+4,n), mod1(4l+2,n)]]\n",
    "        s_new[:, v_new[mod1(k+2,new_n), mod1(l+2,new_n)]] =\n",
    "            samples_matrix[:, v[mod1(4k+4,n), mod1(4l+3,n)]] .* samples_matrix[:, v[mod1(4k+4,n), mod1(4l+4,n)]]\n",
    "    end\n",
    "    return s_new, new_plaqs, (h_new,v_new), new_n\n",
    "end\n",
    "\n",
    "function coarse_plaquettes_overlap(s::Matrix{Float64}, (h,v), n::Int)\n",
    "    new_n = div(n,2)\n",
    "    sizeN = size(s,1)\n",
    "    s_new = Matrix{Float64}(undef, sizeN, 2*new_n*new_n)\n",
    "    (h_new,v_new) = link_indices(new_n)\n",
    "    new_plaqs = plaquettes(new_n, h_new, v_new)\n",
    "    for k in 1:new_n, l in 1:new_n\n",
    "        s_new[:, h_new[mod1(k,new_n), mod1(l,new_n)]] =\n",
    "            (s[:, h[mod1(2k-1,n), mod1(2l-1,n)]] .* s[:, h[mod1(2k,n), mod1(2l-1,n)]])\n",
    "        s_new[:, v_new[mod1(k,new_n), mod1(l,new_n)]] =\n",
    "            (s[:, v[mod1(2k-1,n), mod1(2l-1,n)]] .* s[:, v[mod1(2k-1,n), mod1(2l,n)]])\n",
    "    end\n",
    "    return s_new, new_plaqs, (h_new,v_new), new_n\n",
    "end\n",
    "\n",
    "function coarse_plaquettes_sum(s::Matrix{Float64}, (h, v), n::Int)\n",
    "    new_n = div(n, 2)\n",
    "    sizeN = size(s,1)\n",
    "    s_new = Matrix{Float64}(undef, sizeN, 2*new_n*new_n)\n",
    "    (h_new, v_new) = link_indices(new_n)\n",
    "    new_plaqs = plaquettes(new_n, h_new, v_new)\n",
    "    for k in 1:new_n, l in 1:new_n\n",
    "        hor_sum = s[:, h[mod1(2k-1, n), mod1(2l-1, n)]] .+ s[:, h[mod1(2k, n), mod1(2l-1, n)]]\n",
    "        s_new[:, h_new[mod1(k,new_n), mod1(l,new_n)]] =\n",
    "            map(x -> x > 0 ? 1.0 : x < 0 ? -1.0 : rand(Bool) ? 1.0 : -1.0, hor_sum)\n",
    "        ver_sum = s[:, v[mod1(2k-1, n), mod1(2l-1, n)]] .+ s[:, v[mod1(2k-1, n), mod1(2l, n)]]\n",
    "        s_new[:, v_new[mod1(k,new_n), mod1(l,new_n)]] =\n",
    "            map(x -> x > 0 ? 1.0 : x < 0 ? -1.0 : rand(Bool) ? 1.0 : -1.0, ver_sum)\n",
    "    end\n",
    "    return s_new, new_plaqs, (h_new, v_new), new_n\n",
    "end\n",
    "\n",
    "# optional decimation-style\n",
    "weight(u,K) = exp(K*u)\n",
    "\n",
    "function coarse_grain_2d(s::Matrix{Float64}, (h, v), n::Int, K::Float64)\n",
    "    new_n = n ÷ 2\n",
    "    s_new = Matrix{Float64}(undef, size(s,1), 2*new_n^2)\n",
    "    (h_new, v_new) = link_indices(new_n)\n",
    "    for Kb in 1:new_n, L in 1:new_n\n",
    "        sum_val = zeros(size(s,1))\n",
    "        for u in (1.0, -1.0)\n",
    "            s_left  = s[:, h[mod1(2*Kb-1, n), mod1(2*L-1, n)]]\n",
    "            s_right = s[:, h[mod1(2*Kb-1, n), mod1(2*L,   n)]]\n",
    "            sum_val .+= weight(u,K) * (s_left .* u .* s_right)/(2*cosh(K))\n",
    "        end\n",
    "        s_new[:, h_new[mod1(Kb,new_n), mod1(L,new_n)]] = sum_val\n",
    "    end\n",
    "    for Kb in 1:new_n, L in 1:new_n\n",
    "        sum_val = zeros(size(s,1))\n",
    "        for u in (1.0, -1.0)\n",
    "            s_bottom = s[:, v[mod1(2*Kb-1, n), mod1(2*L-1, n)]]\n",
    "            s_top    = s[:, v[mod1(2*Kb,   n), mod1(2*L-1, n)]]\n",
    "            sum_val .+= weight(u,K) * (s_bottom .* u .* s_top)/(2*cosh(K))\n",
    "        end\n",
    "        s_new[:, v_new[mod1(Kb,new_n), mod1(L,new_n)]] = sum_val\n",
    "    end\n",
    "    new_plaqs = plaquettes(new_n, h_new, v_new)\n",
    "    return s_new, new_plaqs, (h_new, v_new), new_n\n",
    "end\n",
    "\n",
    "# drivers\n",
    "function RG_coarse_4x4(s::Matrix{Float64},(h,v),n::Int,n_steps::Int,K::Float64)\n",
    "    xs = [K]\n",
    "    for _ in 1:n_steps\n",
    "        s, new_plaqs, (h,v), n = coarse_plaquettes_4x4(s,(h,v),n)\n",
    "        push!(xs, multiRISE_links_only_direct(s, new_plaqs))\n",
    "    end\n",
    "    return xs\n",
    "end\n",
    "\n",
    "function RG_coarse_overlap(s::Matrix{Float64},(h,v),n::Int,n_steps::Int,K::Float64)\n",
    "    xs = [K]\n",
    "    for _ in 1:n_steps\n",
    "        s, new_plaqs, (h,v), n = coarse_plaquettes_overlap(s,(h,v),n)\n",
    "        push!(xs, multiRISE_links_only_direct(s, new_plaqs))\n",
    "    end\n",
    "    return xs\n",
    "end\n",
    "\n",
    "function RG_coarse_sum(s::Matrix{Float64},(h,v),n::Int,n_steps::Int,K::Float64)\n",
    "    xs = [K]\n",
    "    for _ in 1:n_steps\n",
    "        s, new_plaqs, (h,v), n = coarse_plaquettes_sum(s,(h,v),n)\n",
    "        push!(xs, multiRISE_links_only_direct(s, new_plaqs))\n",
    "    end\n",
    "    return xs\n",
    "end\n",
    "\n",
    "tanh2RG(K::Float64) = atanh(tanh(K)^2)\n",
    "function RG_flow(K0::Float64, n_steps::Int)\n",
    "    Ks = Float64[K0]\n",
    "    K = K0\n",
    "    for _ in 1:n_steps\n",
    "        K = tanh2RG(K); push!(Ks, K)\n",
    "    end\n",
    "    return Ks\n",
    "end\n",
    "\n",
    "# checkerboard-based example\n",
    "function checkerboard2_rg(samples::Matrix{Float64}, (h,v), n::Int)\n",
    "    @assert n % 2 == 0 \"n must be even\"\n",
    "    new_n = n ÷ 2\n",
    "    N, _  = size(samples)\n",
    "    plaqs = plaquettes(n, h, v)\n",
    "    (h_new,v_new) = link_indices(new_n)\n",
    "    plaqs_new     = plaquettes(new_n, h_new, v_new)\n",
    "    samples_new   = Matrix{Float64}(undef, N, 2*new_n^2)\n",
    "    for p in 1:length(plaqs)\n",
    "        row = div(p-1, n)+1; col = mod(p-1, n)+1\n",
    "        (t, _, _, l) = plaqs[p]\n",
    "        Lp = samples[:,t] .* samples[:,l]\n",
    "        ci = div(row-1, 2) + 1\n",
    "        cj = div(col-1, 2) + 1\n",
    "        idxc = isodd(p) ? h_new[(ci,cj)] : v_new[(ci,cj)]\n",
    "        samples_new[:, idxc] = Lp\n",
    "    end\n",
    "    return samples_new, plaqs_new, (h_new, v_new), new_n\n",
    "end\n",
    "\n",
    "function run_plaquette_rg(samples_matrix, hmap, vmap, n, K, n_steps=3)\n",
    "    K_values = [K]\n",
    "    s_current = samples_matrix\n",
    "    h_current, v_current = hmap, vmap\n",
    "    n_current = n\n",
    "    for step in 1:n_steps\n",
    "        s_new, plaqs_new, (h_new, v_new), n_new = checkerboard2_rg(s_current, (h_current, v_current), n_current)\n",
    "        K_new = multiRISE_links_only_direct(s_new, plaqs_new)\n",
    "        push!(K_values, K_new)\n",
    "        println(\"RG step $step: n = $n_current → $n_new, K = $(K_values[end-1]) → $K_new\")\n",
    "        s_current = s_new; h_current, v_current = h_new, v_new; n_current = n_new\n",
    "    end\n",
    "    return K_values\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Wilson loops and string tension\n",
    "\n",
    "We compute $\\langle W(R,T)\\rangle$ for rectangular loops and extract string tension via area-law:\n",
    "$$\n",
    "\\sigma \\approx -\\frac{1}{A}\\ln \\langle W \\rangle,\\quad A=R\\,T.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function compute_square_wilson_loops(samples::Matrix{Float64},\n",
    "                                     hmap::Dict{Tuple{Int, Int}, Int},\n",
    "                                     vmap::Dict{Tuple{Int, Int}, Int},\n",
    "                                     max_size::Int)\n",
    "    nconfigs, _ = size(samples)\n",
    "    n = Int(sqrt(length(hmap)))\n",
    "    loop_averages = Dict{Tuple{Int, Int}, Float64}()\n",
    "    for R in 1:max_size\n",
    "        loop_sum = 0.0; total_loops = 0\n",
    "        for i in 1:n, j in 1:n\n",
    "            top    = [hmap[(i, mod1(j+x-1, n))] for x in 1:R]\n",
    "            right  = [vmap[(mod1(i+y-1, n), mod1(j+R, n))] for y in 1:R]\n",
    "            bottom = [hmap[(mod1(i+R, n), mod1(j+x-1, n))] for x in R:-1:1]\n",
    "            left   = [vmap[(mod1(i+y-1, n), j)] for y in R:-1:1]\n",
    "            idx = vcat(top, right, bottom, left)\n",
    "            for k in 1:nconfigs\n",
    "                loop_sum += prod(samples[k, idx])\n",
    "            end\n",
    "            total_loops += 1\n",
    "        end\n",
    "        loop_averages[(R, R)] = loop_sum / (nconfigs * total_loops)\n",
    "    end\n",
    "    return loop_averages\n",
    "end\n",
    "\n",
    "function estimate_string_tension(wilson_dict::Dict{Tuple{Int, Int}, Float64})\n",
    "    tension_estimates = Dict{Tuple{Int, Int}, Float64}()\n",
    "    for ((R, T), W) in wilson_dict\n",
    "        if R != T || W <= 0; continue; end\n",
    "        A = R*T\n",
    "        σ = -log(W) / A\n",
    "        tension_estimates[(R, T)] = σ\n",
    "    end\n",
    "    mean_tension = mean(values(tension_estimates))\n",
    "    return tension_estimates, mean_tension\n",
    "end\n",
    "\n",
    "function RG_with_K_and_string_tension(s::Matrix{Float64}, (h,v), n::Int, n_steps::Int, K0::Float64, max_loop_size::Int)\n",
    "    sigmas = Float64[]\n",
    "    s_current = s; (h_current, v_current) = (h, v); n_current = n\n",
    "    for i in 0:n_steps\n",
    "        wilson_loops = compute_square_wilson_loops(s_current, h_current, v_current, max_loop_size)\n",
    "        _, avg_sigma = estimate_string_tension(wilson_loops)\n",
    "        push!(sigmas, avg_sigma)\n",
    "        println(\"Step $i: ⟨σ⟩ = $avg_sigma\")\n",
    "        if i < n_steps\n",
    "            s_current, _, (h_current, v_current), n_current = coarse_plaquettes_overlap(s_current, (h_current, v_current), n_current)\n",
    "        end\n",
    "    end\n",
    "    return sigmas\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Autocorrelation & adaptive sampling helpers\n",
    "\n",
    "These utilities estimate integrated autocorrelation time and suggest thinning. Also included: a parallel-chain sampler for quicker decorrelation (optional)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function measure_actual_autocorrelation(samples::Matrix{Float64}, plaqlist::Vector{NTuple{4, Int}})\n",
    "    energies = compute_plaquette_energy_per_sample(samples, plaqlist)\n",
    "    max_lag = min(length(energies) ÷ 4, 1000)\n",
    "    acf = autocor(energies, 0:max_lag)\n",
    "    tau_int = 1.0\n",
    "    for lag in 1:max_lag\n",
    "        if acf[lag+1] < 0.05\n",
    "            tau_int = 1.0 + 2.0 * sum(acf[2:lag+1]); break\n",
    "        elseif lag == max_lag\n",
    "            tau_int = 1.0 + 2.0 * sum(acf[2:end])\n",
    "            println(\"ACF did not reach 0.05 by lag $max_lag\")\n",
    "        end\n",
    "    end\n",
    "    println(\"Lag-1 ACF: $(acf[2]); τ_int ≈ $tau_int\")\n",
    "    return tau_int, acf\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Example usage (modular; run step-by-step)\n",
    "\n",
    "**Sampling parameters** (edit as needed), then run Metropolis or Cluster, compute diagnostics, learn \\(K\\), apply RG, and estimate string tension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Parameters (edit) ---\n",
    "n = 16\n",
    "K = 0.3\n",
    "nsweeps = 200_000\n",
    "nburn   = 20_000\n",
    "step_interval = 10\n",
    "num_samples = floor(Int, (nsweeps - nburn)/step_interval)\n",
    "\n",
    "# Lattice\n",
    "(hmap, vmap) = link_indices(n)\n",
    "plaqs = plaquettes(n, hmap, vmap)\n",
    "nvars = 2n*n\n",
    "\n",
    "# --- Choose a sampler ---\n",
    "samples_met = zeros(num_samples, nvars)\n",
    "samples_clu = zeros(num_samples, nvars)\n",
    "\n",
    "# Metropolis (reference)\n",
    "# samples_met = metropolis_matrix(n, plaqs, K, nsweeps, nburn, samples_met; step_interval=step_interval)\n",
    "\n",
    "# Cluster (faster decorrelation)\n",
    "samples_clu = cluster_sampler(n, plaqs, K, nsweeps, nburn, samples_clu; step_interval=step_interval)\n",
    "\n",
    "# --- Diagnostics ---\n",
    "energies = compute_plaquette_energy_per_sample(samples_clu, plaqs)\n",
    "histogram(energies, bins=80, xlabel=\"Plaquette energy\", ylabel=\"Count\", title=\"Energy histogram (Cluster)\")\n",
    "acf_vals = compute_and_plot_acf(energies; max_lag=1000)\n",
    "tau = estimate_autocorrelation_length(acf_vals; cutoff=0.05)\n",
    "@show tau\n",
    "\n",
    "# --- Learn K from samples ---\n",
    "K_rise  = multiRISE_links_only_direct(samples_clu, plaqs)\n",
    "K_pl    = PL_links(samples_clu, plaqs)\n",
    "K_ml    = ML_estimator_plaquette(samples_clu, plaqs)\n",
    "@show K_rise K_pl K_ml\n",
    "\n",
    "# --- RG flows (pick a scheme) ---\n",
    "K_flow_overlap = RG_coarse_overlap(samples_clu, (hmap,vmap), n, 3, K)\n",
    "K_flow_sum     = RG_coarse_sum(samples_clu, (hmap,vmap), n, 3, K)\n",
    "K_flow_4x4     = RG_coarse_4x4(samples_clu, (hmap,vmap), n, 3, K)\n",
    "\n",
    "# analytic flow (for comparison)\n",
    "K_flow_analytic = RG_flow(K, 3)\n",
    "\n",
    "# --- Wilson loops & string tension along RG ---\n",
    "sigmas = RG_with_K_and_string_tension(samples_clu, (hmap, vmap), n, 3, K, 2)\n",
    "\n",
    "# --- Plot flows ---\n",
    "plot(0:3, K_flow_overlap, lw=2, marker=:circle, label=\"RG overlap\")\n",
    "plot!(0:3, K_flow_sum,     lw=2, marker=:square, label=\"RG sum\")\n",
    "plot!(0:3, K_flow_4x4,     lw=2, marker=:utriangle, label=\"RG 4x4\")\n",
    "plot!(0:3, K_flow_analytic, lw=2, marker=:diamond, label=\"analytic tanh^2 map\")\n",
    "xlabel!(\"RG step\"); ylabel!(\"K\"); title!(\"RG flows of K\")\n",
    "\n",
    "plot(0:3, sigmas, lw=2, marker=:circle, xlabel=\"RG step\", ylabel=\"σ\", title=\"String tension vs RG step\", label=\"σ\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
