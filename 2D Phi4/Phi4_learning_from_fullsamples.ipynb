{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to generate samples and learn the values of $\\lambda$ and $m2$ for various sample sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using AdvancedHMC, ForwardDiff\n",
    "using LogDensityProblems, LinearAlgebra, Random, Statistics, JuMP, Ipopt, Plots\n",
    "\n",
    "# Define the Phi4Model structure for 2D\n",
    "struct Phi4Model2D\n",
    "    lattice_size::Int  # Lattice size (NxN)\n",
    "    lambda::Float64    # Quartic coupling constant\n",
    "    m2 :: Float64      # Mass term squared\n",
    "end\n",
    "\n",
    "# Function to calculate the total energy (kinetic + potential) of a 2D field configuration\n",
    "function calculate_energy_2d(phi::Matrix{T}, model::Phi4Model2D) where T<:Real\n",
    "    N = size(phi, 1)\n",
    "    kinetic_energy = 0.0\n",
    "    potential_energy = 0.0\n",
    "    \n",
    "    # Loop through all the lattice points and calculate kinetic and potential terms\n",
    "    for i in 1:N, j in 1:N\n",
    "        # Kinetic term: sum over nearest neighbors (discrete Laplacian)\n",
    "        i_right = mod1(i + 1, N)\n",
    "        j_up = mod1(j + 1, N)\n",
    "        kinetic_energy += 0.5 * ((phi[i, j] - phi[i_right, j])^2 + (phi[i, j] - phi[i, j_up])^2)\n",
    "        \n",
    "        # Potential term: phi^4 interaction + mass term\n",
    "        potential_energy += 0.5 * model.m2 * phi[i, j]^2 + 0.25 * model.lambda * phi[i, j]^4\n",
    "    end\n",
    "    \n",
    "    return kinetic_energy + potential_energy\n",
    "end\n",
    "\n",
    "# Define the Phi4TargetDensity structure for 2D\n",
    "struct Phi4TargetDensity2D\n",
    "    dim::Int\n",
    "    model::Phi4Model2D\n",
    "end\n",
    "\n",
    "# Implement the log-density function for Phi4 2D\n",
    "function LogDensityProblems.logdensity(p::Phi4TargetDensity2D, phi_vector::Vector{T}) where T<:Real\n",
    "    # Reshape the vector back into a 2D matrix\n",
    "    N = p.model.lattice_size\n",
    "    phi = reshape(phi_vector, N, N)\n",
    "    return -calculate_energy_2d(phi, p.model)\n",
    "end\n",
    "\n",
    "LogDensityProblems.dimension(p::Phi4TargetDensity2D) = p.model.lattice_size^2\n",
    "LogDensityProblems.capabilities(::Type{Phi4TargetDensity2D}) = LogDensityProblems.LogDensityOrder{0}()\n",
    "\n",
    "# Function to generate data for the Phi4 model in 2D using Hamiltonian Monte Carlo (HMC)\n",
    "function generate_phi4_data_hmc_2d(model::Phi4Model2D, n_samples::Int, n_adapts::Int = 1000)\n",
    "    lattice_size = model.lattice_size\n",
    "    phi4_target = Phi4TargetDensity2D(lattice_size^2, model)\n",
    "\n",
    "    # Define the initial 2D field configuration (NxN matrix)\n",
    "    initial_phi = randn(lattice_size, lattice_size)\n",
    "\n",
    "    # Define a Hamiltonian system\n",
    "    metric = DiagEuclideanMetric(lattice_size^2)\n",
    "    hamiltonian = Hamiltonian(metric, phi4_target, ForwardDiff)\n",
    "\n",
    "    # Define a leapfrog solver with an initial step size chosen heuristically\n",
    "    initial_epsilon = find_good_stepsize(hamiltonian, vec(initial_phi))\n",
    "    integrator = Leapfrog(initial_epsilon)\n",
    "\n",
    "    # Define an HMC sampler with Multinomial sampling and Generalized No-U-Turn\n",
    "    kernel = HMCKernel(Trajectory{MultinomialTS}(integrator, GeneralisedNoUTurn()))\n",
    "    adaptor = StanHMCAdaptor(MassMatrixAdaptor(metric), StepSizeAdaptor(0.8, integrator))\n",
    "\n",
    "    # Run the sampler to draw samples from the Phi4 model\n",
    "    samples_vector, stats = sample(hamiltonian, kernel, vec(initial_phi), n_samples, adaptor, n_adapts; progress=false)\n",
    "\n",
    "    # Reshape the samples back into 2D matrices\n",
    "    samples = [reshape(sample, lattice_size, lattice_size) for sample in samples_vector]\n",
    "\n",
    "    return samples\n",
    "end\n",
    "\n",
    "# Score matching objective function for 2D\n",
    "function score_matching_objective_2d(lambda::T, m2::T, data::Vector{Matrix{Float64}}) where T<:Real\n",
    "    N = size(data[1], 1)\n",
    "    n_samples = length(data)\n",
    "    obj = zero(T)\n",
    "\n",
    "    for sample in 1:n_samples\n",
    "        phi = data[sample]\n",
    "        for i in 1:N, j in 1:N\n",
    "            x_ij = phi[i, j]\n",
    "            # Nearest neighbors with periodic boundary conditions\n",
    "            x_left = phi[mod1(i - 1, N), j]\n",
    "            x_right = phi[mod1(i + 1, N), j]\n",
    "            x_down = phi[i, mod1(j - 1, N)]\n",
    "            x_up = phi[i, mod1(j + 1, N)]\n",
    "            # Corrected kinetic term gradient (discrete Laplacian)\n",
    "            kinetic_term = -(4 * x_ij - x_left - x_right - x_up - x_down)\n",
    "\n",
    "            # Score function s(x_ij) including full kinetic term\n",
    "            score_ij = kinetic_term - (m2 * x_ij + lambda * x_ij^3)\n",
    "            # Second derivative s'(x_ij)\n",
    "            s_prime = -(m2 + 3 * lambda * x_ij^2 + 4)\n",
    "            # Add to the objective\n",
    "            obj += T(0.5) * score_ij^2 + s_prime\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return obj / n_samples\n",
    "end\n",
    "\n",
    "# Function to estimate the parameters λ and m² using score matching in 2D\n",
    "function estimate_parameters_score_matching_2d(data::Vector{Matrix{Float64}})\n",
    "    model = Model(Ipopt.Optimizer)\n",
    "    set_optimizer_attribute(model, \"print_level\", 0)\n",
    "    \n",
    "    @variable(model, λ)\n",
    "    @variable(model, m2)\n",
    "    \n",
    "    register(model, :score_matching_obj, 2, (λ, m2) -> score_matching_objective_2d(λ, m2, data), autodiff=true)\n",
    "    \n",
    "    @NLobjective(model, Min, score_matching_obj(λ, m2))\n",
    "    \n",
    "    optimize!(model)\n",
    "    \n",
    "    if !(termination_status(model) in [MOI.OPTIMAL, MOI.LOCALLY_SOLVED])\n",
    "        @warn \"Optimization did not converge to an optimal solution\"\n",
    "    end\n",
    "    \n",
    "    estimated_lambda = value(λ)\n",
    "    estimated_m2 = value(m2)\n",
    "    \n",
    "    return estimated_lambda, estimated_m2\n",
    "end\n",
    "\n",
    "# Function to plot errors for λ and m² versus sample sizes\n",
    "function plot_errors_vs_sample_size(sample_sizes::Vector{Int}, errors_lambda::Vector{Float64}, errors_m2::Vector{Float64})\n",
    "    # Compute the 1/sqrt(n) reference line\n",
    "    reference_errors = 1 ./ sqrt.(sample_sizes)\n",
    "    \n",
    "    # Scale the reference line to start from the first error point for λ and m²\n",
    "    scaled_ref_lambda = reference_errors * (errors_lambda[1] / reference_errors[1])\n",
    "    scaled_ref_m2 = reference_errors * (errors_m2[1] / reference_errors[1])\n",
    "\n",
    "    # Plot errors in λ vs sample size\n",
    "    p1 = plot(sample_sizes, errors_lambda, xlabel=\"Sample Size\", ylabel=\"Error in λ\", \n",
    "              title=\"Error in λ vs Sample Size\", marker=:circle, legend=:topright, label=\"Error in λ\", xscale=:log10, yscale=:log10,lw=2,palette = :RdBu_4)\n",
    "    plot!(sample_sizes, scaled_ref_lambda, linestyle=:dash, color=:black, label=\"1/√n\")\n",
    "\n",
    "    # Plot errors in m² vs sample size\n",
    "    p2 = plot(sample_sizes, errors_m2, xlabel=\"Sample Size\", ylabel=\"Error in m²\", \n",
    "              title=\"Error in m² vs Sample Size\", marker=:circle, legend=:topright, label=\"Error in m²\", xscale=:log10, yscale=:log10,lw = 2,palette = :RdBu_4)\n",
    "    plot!(sample_sizes, scaled_ref_m2, linestyle=:dash, color=:black, label=\"1/√n\")\n",
    "\n",
    "    return p1, p2\n",
    "end\n",
    "\n",
    "# Main function\n",
    "\n",
    "Random.seed!(12345)\n",
    "lattice_size = 4\n",
    "n_reps = 30\n",
    "true_model   = Phi4Model2D(lattice_size, 0.5, 0.75)  # Use m²\n",
    "\n",
    "# single sample‑size in this example\n",
    "sample_sizes = [2^(i) for i in 10:20]\n",
    "N = length(sample_sizes)\n",
    "\n",
    "# storage: each row = one repetition, each column = one sample_size\n",
    "errors_λ  = zeros(n_reps, N)\n",
    "errors_m2 = zeros(n_reps, N)\n",
    "\n",
    "for rep in 1:n_reps\n",
    "    println(\"=== rep $rep of $n_reps ===\")\n",
    "    for (i, n_samples) in enumerate(sample_sizes)\n",
    "        println(\"  processing n_samples = $n_samples …\")\n",
    "        samples = generate_phi4_data_hmc_2d(true_model, n_samples)\n",
    "        λ_est, m2_est = estimate_parameters_score_matching_2d(samples)\n",
    "\n",
    "        errors_λ[rep,  i] = abs(λ_est  - true_model.lambda)\n",
    "        errors_m2[rep, i] = abs(m2_est - true_model.m2)\n",
    "    end\n",
    "end\n",
    "\n",
    "# average across repetitions\n",
    "mean_err_λ  = vec(mean(errors_λ,  dims=1))\n",
    "mean_err_m2 = vec(mean(errors_m2, dims=1))\n",
    "\n",
    "# now plot the **averaged** errors\n",
    "p1, p2 = plot_errors_vs_sample_size(sample_sizes, mean_err_λ, mean_err_m2)\n",
    "\n",
    "savefig(p1, \"error_in_lambda_avg.png\")\n",
    "savefig(p2, \"error_in_m2_avg.png\")\n",
    "display(p1)\n",
    "display(p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = palette(:RdBu_4)\n",
    "# take the last element (the deep blue)\n",
    "blue = colors[end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function plot_errors_vs_sample_size(sample_sizes::Vector{Int}, errors_lambda::Vector{Float64}, errors_m2::Vector{Float64})\n",
    "    # Compute the 1/sqrt(n) reference line\n",
    "    reference_errors = 1 ./ sqrt.(sample_sizes)\n",
    "    \n",
    "    # Scale the reference line to start from the first error point for λ and m²\n",
    "    scaled_ref_lambda = reference_errors * (errors_lambda[1] / reference_errors[1])\n",
    "    scaled_ref_m2 = reference_errors * (errors_m2[1] / reference_errors[1])\n",
    "\n",
    "    # Plot errors in λ vs sample size\n",
    "    p1 = plot(sample_sizes, errors_lambda, xlabel=\"Sample Size\", ylabel=\"Error in λ\", \n",
    "              title=\"Error in λ vs Sample Size\", marker=:circle, legend=:topright, label=\"Error in λ\", xscale=:log10, yscale=:log10,lw=2,palette = :RdBu_4)\n",
    "    plot!(sample_sizes, scaled_ref_lambda, linestyle=:dash, color=:black, label=\"1/√n\")\n",
    "\n",
    "    # Plot errors in m² vs sample size\n",
    "    p2 = plot(sample_sizes, errors_m2, xlabel=\"Sample Size\", ylabel=\"Error in m²\", \n",
    "              title=\"Error in m² vs Sample Size\", marker=:circle, legend=:topright, label=\"Error in m²\", xscale=:log10, yscale=:log10,lw = 2,color = blue)\n",
    "    plot!(sample_sizes, scaled_ref_m2, linestyle=:dash, color=:black, label=\"1/√n\")\n",
    "\n",
    "    return p1, p2\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1, p2 = plot_errors_vs_sample_size(sample_sizes, mean_err_λ, mean_err_m2)\n",
    "\n",
    "savefig(p1, \"error_in_lambda_avg.png\")\n",
    "savefig(p2, \"error_in_m2_avg.png\")\n",
    "display(p1)\n",
    "display(p2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.4",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
