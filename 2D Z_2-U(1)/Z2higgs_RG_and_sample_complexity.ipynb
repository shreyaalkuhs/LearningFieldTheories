{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to generate samples using the standard Metropolis Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Random, Statistics, Optim, SpecialFunctions\n",
    "\n",
    "# -----------------------------\n",
    "# Helper: Periodic Boundary Conditions\n",
    "# -----------------------------\n",
    "periodic(i, L) = mod(i - 1, L) + 1\n",
    "\n",
    "# -----------------------------\n",
    "# Lattice Initialization\n",
    "# -----------------------------\n",
    "\"\"\"\n",
    "    initialize_lattice(L)\n",
    "\n",
    "Creates an L×L lattice:\n",
    "  - sigma: Ising spins (±1)\n",
    "  - U1: Horizontal gauge links (U(1) elements: exp(iθ))\n",
    "  - U2: Vertical gauge links (U(1) elements)\n",
    "\"\"\"\n",
    "function initialize_lattice(L)\n",
    "    sigma = [rand(Bool) ? 1 : -1 for i in 1:L, j in 1:L]\n",
    "    U1    = [exp(1im * 2π * rand()) for i in 1:L, j in 1:L]\n",
    "    U2    = [exp(1im * 2π * rand()) for i in 1:L, j in 1:L]\n",
    "    return sigma, U1, U2\n",
    "end\n",
    "\n",
    "# -----------------------------\n",
    "# Total Energy Computation\n",
    "# -----------------------------\n",
    "\"\"\"\n",
    "    total_energy(sigma, U1, U2, K, beta)\n",
    "\n",
    "Compute the total energy of the configuration.\n",
    "- Gauge energy: sum over plaquettes,\n",
    "    where a plaquette at (i,j) is\n",
    "      P = U1[i,j] * U2[i, j+1] * conj(U1[i+1,j]) * conj(U2[i,j])\n",
    "  and the contribution is -K·Re(P).\n",
    "- Matter energy: sum over nearest neighbors (horizontal and vertical),\n",
    "    where the coupling is -β · (sigma(x)·Re(U(x,y))·sigma(y)).\n",
    "\"\"\"\n",
    "function total_energy(sigma, U1, U2, K, beta)\n",
    "    L = size(sigma, 1)\n",
    "    E = 0.0\n",
    "    # Gauge part: loop over sites and form plaquettes.\n",
    "    for i in 1:L, j in 1:L\n",
    "        jp = periodic(j+1, L)\n",
    "        ip = periodic(i+1, L)\n",
    "        P = U1[i,j] * U2[i, jp] * conj(U1[ip, j]) * conj(U2[i,j])\n",
    "        E += -K * real(P)\n",
    "    end\n",
    "    # Matter part: horizontal and vertical nearest neighbors.\n",
    "    for i in 1:L, j in 1:L\n",
    "        jp = periodic(j+1, L)\n",
    "        ip = periodic(i+1, L)\n",
    "        E += -beta * ( sigma[i,j] * real(U1[i,j]) * sigma[i, jp] +\n",
    "                       sigma[i,j] * real(U2[i,j]) * sigma[ip, j] )\n",
    "    end\n",
    "    return E\n",
    "end\n",
    "\n",
    "# -----------------------------\n",
    "# Metropolis Sweep Update\n",
    "# -----------------------------\n",
    "\"\"\"\n",
    "    metropolis_sweep!(sigma, U1, U2, K, beta; eps_U=0.5)\n",
    "\n",
    "Performs one full sweep over the lattice:\n",
    "  - For each spin: propose a flip (change sign) and accept using Metropolis rule.\n",
    "  - For each gauge link (U1 and U2): propose a new link by rotating the current link \n",
    "    by δ (with δ uniformly drawn from [-eps_U, eps_U]) and accept with probability exp(-ΔE).\n",
    "\"\"\"\n",
    "function metropolis_sweep!(sigma, U1, U2, K, beta; eps_U=0.5)\n",
    "    L = size(sigma,1)\n",
    "    \n",
    "    # --- Update spins ---\n",
    "    for i in 1:L, j in 1:L\n",
    "        # Compute energy before flipping\n",
    "        E_old = total_energy(sigma, U1, U2, K, beta)\n",
    "        sigma[i,j] *= -1  # propose flip\n",
    "        E_new = total_energy(sigma, U1, U2, K, beta)\n",
    "        ΔE = E_new - E_old\n",
    "        if rand() >= exp(-ΔE)\n",
    "            sigma[i,j] *= -1  # reject: flip back\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # --- Update horizontal gauge links (U1) ---\n",
    "    for i in 1:L, j in 1:L\n",
    "        old_link = U1[i,j]\n",
    "        E_old = total_energy(sigma, U1, U2, K, beta)\n",
    "        δ = rand()*2*eps_U - eps_U\n",
    "        U1[i,j] = old_link * exp(1im * δ)  # propose update\n",
    "        E_new = total_energy(sigma, U1, U2, K, beta)\n",
    "        ΔE = E_new - E_old\n",
    "        if rand() >= exp(-ΔE)\n",
    "            U1[i,j] = old_link  # reject update\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # --- Update vertical gauge links (U2) ---\n",
    "    for i in 1:L, j in 1:L\n",
    "        old_link = U2[i,j]\n",
    "        E_old = total_energy(sigma, U1, U2, K, beta)\n",
    "        δ = rand()*2*eps_U - eps_U\n",
    "        U2[i,j] = old_link * exp(1im * δ)\n",
    "        E_new = total_energy(sigma, U1, U2, K, beta)\n",
    "        ΔE = E_new - E_old\n",
    "        if rand() >= exp(-ΔE)\n",
    "            U2[i,j] = old_link\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "# -----------------------------\n",
    "# Sample Generation\n",
    "# -----------------------------\n",
    "\"\"\"\n",
    "    generate_samples(L, K, beta, n_thermal, n_samples, sweeps_between)\n",
    "\n",
    "Thermalizes the lattice for n_thermal full sweeps, then collects n_samples \n",
    "samples, performing sweeps_between full sweeps between samples.\n",
    "Each sample is stored (deep copied) along with its energy per site.\n",
    "\"\"\"\n",
    "function generate_samples(L, K, beta, n_thermal, n_samples, sweeps_between)\n",
    "    sigma, U1, U2 = initialize_lattice(L)\n",
    "    # Thermalize\n",
    "    for s in 1:n_thermal\n",
    "        metropolis_sweep!(sigma, U1, U2, K, beta)\n",
    "    end\n",
    "    samples = Vector{Tuple{Array{Int,2}, Array{ComplexF64,2}, Array{ComplexF64,2}}}(undef, n_samples)\n",
    "    energies = zeros(n_samples)\n",
    "    for s in 1:n_samples\n",
    "        for k in 1:sweeps_between\n",
    "            metropolis_sweep!(sigma, U1, U2, K, beta)\n",
    "        end\n",
    "        samples[s] = (deepcopy(sigma), deepcopy(U1), deepcopy(U2))\n",
    "        energies[s] = total_energy(sigma, U1, U2, K, beta) / (L^2)\n",
    "    end\n",
    "    return samples, energies\n",
    "end\n",
    "\n",
    "# -----------------------------\n",
    "# Staples for Gauge Pseudolikelihood\n",
    "# -----------------------------\n",
    "\n",
    "# -----------------------------\n",
    "# Main: Run Simulation and Parameter Estimation\n",
    "# -----------------------------\n",
    "# Simulation parameters\n",
    "L = 7\n",
    "K_true = 1.2\n",
    "beta_true = 0.34\n",
    "n_thermal = 100         # Number of sweeps for thermalization\n",
    "n_samples = 10000          # Number of samples to collect\n",
    "sweeps_between = 10     # Number of full sweeps between samples\n",
    "\n",
    "# Generate samples from the model.\n",
    "samples, energies = generate_samples(L, K_true, beta_true, n_thermal, n_samples, sweeps_between)\n",
    "println(\"Collected \", n_samples, \" samples.\")\n",
    "println(\"Average energy per site: \", mean(energies))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now code to learn $\\beta$ using Pseudo-likelihood. \n",
    "\\begin{align*}\n",
    "    P\\left(\\sigma_{ij} \\mid \\text{neighbors}\\right) &= \\frac{\\exp\\Bigl(\\beta\\,\\sigma_{ij}\\,H_{ij}\\Bigr)}{2\\cosh\\Bigl(\\beta\\,H_{ij}\\Bigr)}\\\\\n",
    "    H_{ij} &= \\Re(U_{1,i,j-1})\\,\\sigma_{i,j-1} + \\Re(U_{1,i,j})\\,\\sigma_{i,j+1} + \\Re(U_{2,i-1,j})\\,\\sigma_{i-1,j} + \\Re(U_{2,i,j})\\,\\sigma_{i+1,j}.\n",
    "\\end{align*}\n",
    "The overall pseudolikelihood for the lattice is given by\n",
    "\\begin{align*}\n",
    "    \\mathcal{PL}(\\beta) = \\prod_{i,j} \\frac{\\exp\\Bigl(\\beta\\,\\sigma_{ij}\\,H_{ij}\\Bigr)}\n",
    "{2\\cosh\\Bigl(\\beta\\,H_{ij}\\Bigr)}.\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Optim, SpecialFunctions\n",
    "\n",
    "# Compute the log pseudolikelihood for one configuration.\n",
    "# For each site (i,j), the local effective field is given by:\n",
    "#   H[i,j] = real(U1[i,j-1])*σ[i,j-1] + real(U1[i,j])*σ[i,j+1]\n",
    "#          + real(U2[i-1,j])*σ[i-1,j] + real(U2[i,j])*σ[i+1,j]\n",
    "function log_pseudolikelihood_sample(beta, sigma, U1, U2)\n",
    "    L = size(sigma, 1)\n",
    "    lp = 0.0\n",
    "    for i in 1:L, j in 1:L\n",
    "        # Apply periodic boundary conditions for neighbors\n",
    "        left_j  = periodic(j - 1, L)\n",
    "        right_j = periodic(j + 1, L)\n",
    "        up_i    = periodic(i - 1, L)\n",
    "        down_i  = periodic(i + 1, L)\n",
    "\n",
    "        # Local field contributions from the four neighbors\n",
    "        H_left  = real(U1[i, left_j])  * sigma[i, left_j]\n",
    "        H_right = real(U1[i, j])         * sigma[i, right_j]\n",
    "        H_up    = real(U2[up_i, j])      * sigma[up_i, j]\n",
    "        H_down  = real(U2[i, j])         * sigma[down_i, j]\n",
    "        H = H_left + H_right + H_up + H_down\n",
    "\n",
    "        # Log pseudolikelihood contribution for site (i,j)\n",
    "        lp += beta * sigma[i,j] * H - log(2 * cosh(beta * H))\n",
    "    end\n",
    "    return lp\n",
    "end\n",
    "\n",
    "# Total (negative) log pseudolikelihood over all samples.\n",
    "# We sum the contributions from each sample configuration.\n",
    "function neg_total_log_pseudolikelihood(beta, samples)\n",
    "    total_lp = 0.0\n",
    "    for (sigma, U1, U2) in samples\n",
    "        total_lp += log_pseudolikelihood_sample(beta, sigma, U1, U2)\n",
    "    end\n",
    "    return -total_lp  # negative because we maximize the log pseudolikelihood\n",
    "end\n",
    "\n",
    "# Now, use the Optim package to learn beta.\n",
    "# We'll minimize the negative total log pseudolikelihood.\n",
    "# Here, we use a search interval [0.0, 2.0]; you can adjust it as needed.\n",
    "result = optimize(b -> neg_total_log_pseudolikelihood(b, samples), 0.0, 2.0)\n",
    "beta_est = Optim.minimizer(result)\n",
    "println(\"Estimated beta from pseudolikelihood: \", beta_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the code to learn $K$ values, after fixing $\\beta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Hyvärinen Score for U1 and U2 ---\n",
    "# Here we work in the angular (phase) representation.\n",
    "# For a gauge link U = exp(i θ), the contribution to the Hyvärinen score is:\n",
    "#   (1/2)[(dE/dθ)²] - (d²E/dθ²)\n",
    "# where dE/dθ and d²E/dθ² include contributions from both the matter and the gauge parts.\n",
    "\n",
    "# Hyvärinen score for U1 links\n",
    "function hyvarinen_score_U1(sigma, U1, U2, K, beta)\n",
    "    L = size(sigma, 1)\n",
    "    score = 0.0\n",
    "    for i in 1:L, j in 1:L\n",
    "        # Get the phase of U1[i,j]\n",
    "        θ = angle(U1[i,j])\n",
    "        \n",
    "        # -- Matter contribution (only one term involves U1[i,j]) --\n",
    "        # Matter term: -β σ[i,j] cos(θ) σ[i,j+1]\n",
    "        jp = periodic(j+1, L)\n",
    "        dE_matter = beta * sigma[i,j] * sigma[i,jp] * sin(θ)\n",
    "        d2E_matter = beta * sigma[i,j] * sigma[i,jp] * cos(θ)\n",
    "        \n",
    "        # -- Gauge contributions --\n",
    "        # U1[i,j] appears in two plaquettes:\n",
    "        # 1. Plaquette at (i,j): U1 appears directly.\n",
    "        jp_plaq = periodic(j+1, L)\n",
    "        ip_plaq = periodic(i+1, L)\n",
    "        # The corresponding term is: -K * cos(θ + φ₁),\n",
    "        # where φ₁ = arg( U2[i, jp_plaq] * conj(U1[ip_plaq,j]) * conj(U2[i,j]) )\n",
    "        A = U2[i, jp_plaq] * conj(U1[ip_plaq,j]) * conj(U2[i,j])\n",
    "        φ₁ = angle(A)\n",
    "        dE_gauge1 = K * sin(θ + φ₁)\n",
    "        d2E_gauge1 = K * cos(θ + φ₁)\n",
    "        \n",
    "        # 2. Plaquette at (i-1,j): U1 appears as the complex conjugate.\n",
    "        im = periodic(i-1, L)\n",
    "        # For the plaquette at (i-1,j):\n",
    "        # Term = -K * cos(φ₂ - θ), with φ₂ = arg( U1[im,j] * U2[im, periodic(j+1,L)] * conj(U2[im,j]) )\n",
    "        jp_im = periodic(j+1, L)\n",
    "        A2 = U1[im, j] * U2[im, jp_im] * conj(U2[im,j])\n",
    "        φ₂ = angle(A2)\n",
    "        # Derivative: d/dθ [ -K cos(φ₂ - θ) ] = -K * sin(φ₂ - θ)\n",
    "        dE_gauge2 = -K * sin(φ₂ - θ)\n",
    "        d2E_gauge2 = K * cos(φ₂ - θ)\n",
    "        \n",
    "        # Total derivatives at U1[i,j]\n",
    "        dE_total = dE_matter + dE_gauge1 + dE_gauge2\n",
    "        d2E_total = d2E_matter + d2E_gauge1 + d2E_gauge2\n",
    "        \n",
    "        # Add Hyvärinen score contribution for this link.\n",
    "        score += 0.5 * dE_total^2 - d2E_total\n",
    "    end\n",
    "    return score\n",
    "end\n",
    "\n",
    "# Hyvärinen score for U2 links\n",
    "function hyvarinen_score_U2(sigma, U1, U2, K, beta)\n",
    "    L = size(sigma, 1)\n",
    "    score = 0.0\n",
    "    for i in 1:L, j in 1:L\n",
    "        # Get the phase of U2[i,j]\n",
    "        θ = angle(U2[i,j])\n",
    "        \n",
    "        # -- Matter contribution (only one term involves U2[i,j]) --\n",
    "        # Matter term: -β σ[i,j] cos(θ) σ[i+1,j]\n",
    "        ip = periodic(i+1, L)\n",
    "        dE_matter = beta * sigma[i,j] * sigma[ip,j] * sin(θ)\n",
    "        d2E_matter = beta * sigma[i,j] * sigma[ip,j] * cos(θ)\n",
    "        \n",
    "        # -- Gauge contributions --\n",
    "        # U2[i,j] appears in two plaquettes:\n",
    "        # 1. Plaquette at (i,j): Here U2[i,j] enters as its complex conjugate.\n",
    "        jp = periodic(j+1, L)\n",
    "        ip_plaq = periodic(i+1, L)\n",
    "        # For plaquette (i,j): term = -K * cos(φ₃ - θ),\n",
    "        # with φ₃ = arg( U1[i,j] * U2[i,jp] * conj(U1[ip,j]) )\n",
    "        A = U1[i,j] * U2[i, jp] * conj(U1[ip,j])\n",
    "        φ₃ = angle(A)\n",
    "        dE_gauge1 = K * sin(φ₃ - θ)\n",
    "        d2E_gauge1 = K * cos(φ₃ - θ)\n",
    "        \n",
    "        # 2. Plaquette at (i, j-1): Here U2[i,j] appears directly.\n",
    "        jm = periodic(j-1, L)\n",
    "        # For plaquette (i,j-1): term = -K * cos(θ + φ₄),\n",
    "        # where φ₄ = arg( U1[i,j-1] * conj(U1[periodic(i+1,L), j-1]) * conj(U2[i,j-1]) )\n",
    "        B = U1[i, jm] * conj(U1[periodic(i+1,L), jm]) * conj(U2[i, jm])\n",
    "        φ₄ = angle(B)\n",
    "        dE_gauge2 = K * sin(θ + φ₄)\n",
    "        d2E_gauge2 = K * cos(θ + φ₄)\n",
    "        \n",
    "        dE_total = dE_matter + dE_gauge1 + dE_gauge2\n",
    "        d2E_total = d2E_matter + d2E_gauge1 + d2E_gauge2\n",
    "        \n",
    "        score += 0.5 * dE_total^2 - d2E_total\n",
    "    end\n",
    "    return score\n",
    "end\n",
    "\n",
    "function hyvarinen_score_gauge(sigma, U1, U2, K, beta)\n",
    "    score_U1 = hyvarinen_score_U1(sigma, U1, U2, K, beta)\n",
    "    score_U2 = hyvarinen_score_U2(sigma, U1, U2, K, beta)\n",
    "    return score_U1 + score_U2\n",
    "end\n",
    "\n",
    "function objective_K(samples::Vector{Tuple{Matrix{Int64}, Matrix{ComplexF64}, Matrix{ComplexF64}}},K::Float64, beta_est::Float64)\n",
    "    total_score = 0.0\n",
    "    for (sigma, U1, U2) in samples\n",
    "        total_score += hyvarinen_score_gauge(sigma, U1, U2, K, beta_est)\n",
    "    end\n",
    "    return total_score / length(samples)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the code to learn $\\beta$ and $K$ for various sample sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Optim, Statistics, Plots\n",
    "\n",
    "# --- Parameters ---\n",
    "L = 4\n",
    "K_true = 2.5\n",
    "beta_true = 0.25\n",
    "n_thermal = 100         # Number of sweeps for thermalization\n",
    "sweeps_between = 1     # Sweeps between samples\n",
    "\n",
    "# Define a range of sample sizes to test.\n",
    "sample_sizes = [4000*2^i for i in 4:10]\n",
    "\n",
    "# Arrays to store the average absolute errors for beta and K.\n",
    "beta_errors_avg = Float64[]\n",
    "K_errors_avg = Float64[]\n",
    "\n",
    "# Number of independent runs for each sample size.\n",
    "n_runs = 1\n",
    "\n",
    "# Loop over different sample sizes.\n",
    "for n_samples in sample_sizes\n",
    "    println(\"Running for n_samples = $n_samples\")\n",
    "    run_beta_errors = Float64[]\n",
    "    run_K_errors = Float64[]\n",
    "    \n",
    "    for run in 1:n_runs\n",
    "        println(\"  Run $run\")\n",
    "        # Generate samples for the current sample size.\n",
    "        samples, energies = generate_samples(L, K_true, beta_true, n_thermal, n_samples, sweeps_between)\n",
    "        println(eltype(samples))\n",
    "        # -----------------------------\n",
    "        # Learn beta using the pseudolikelihood\n",
    "        # -----------------------------\n",
    "\n",
    "        # Optimize beta (assume search interval [0,2]; adjust if necessary).\n",
    "        result_beta = optimize(b -> neg_total_log_pseudolikelihood(b,samples), 0.0, 2.0)\n",
    "        beta_est = Optim.minimizer(result_beta)\n",
    "        println(\"    Estimated beta: \", beta_est)\n",
    "        \n",
    "        # -----------------------------\n",
    "        # Learn K using the Hyvärinen score\n",
    "        # -----------------------------\n",
    "        \n",
    "        # Optimize K (assume search interval [0,10]; adjust if needed).\n",
    "        result_K = optimize(K -> objective_K(samples,K,beta_est), 0.1, 10.0)\n",
    "        K_est = Optim.minimizer(result_K)\n",
    "        println(\"    Estimated K: \", K_est)\n",
    "        \n",
    "        # Record absolute errors for this run.\n",
    "        push!(run_beta_errors, abs(beta_est - beta_true))\n",
    "        push!(run_K_errors, abs(K_est - K_true))\n",
    "    end\n",
    "    \n",
    "    # Average the errors over the runs.\n",
    "    push!(beta_errors_avg, mean(run_beta_errors))\n",
    "    push!(K_errors_avg, mean(run_K_errors))\n",
    "end\n",
    "\n",
    "# -----------------------------\n",
    "# Plotting the Errors vs. Sample Size\n",
    "# -----------------------------\n",
    "p = plot(sample_sizes, beta_errors_avg, lw=2, marker=:circle, xscale=:log10, yscale=:log10,\n",
    "         xlabel=\"Number of samples\", ylabel=\"Absolute error\", label=\"β error\",\n",
    "         title=\"Parameter Estimation Errors vs. Sample Size\")\n",
    "plot!(sample_sizes, K_errors_avg, lw=2, marker=:square, xscale=:log10, yscale=:log10,\n",
    "      label=\"K error\")\n",
    "display(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "# assume `sample_sizes`, `beta_errors_avg`, and `K_errors_avg` already defined\n",
    "\n",
    "# restrict to the range you are plotting (starts at index 5)\n",
    "Ns_beta   = sample_sizes\n",
    "err_beta  = beta_errors_avg\n",
    "Ns_K      = sample_sizes\n",
    "err_K     = K_errors_avg\n",
    "\n",
    "# ---- 1/√N reference curves (anchored at first data point) ----\n",
    "ref_beta = err_beta[1] .* sqrt.(Ns_beta[1] ./ Ns_beta)  # passes through (Ns_beta[1], err_beta[1])\n",
    "ref_K    = err_K[1]    .* sqrt.(Ns_K[1]    ./ Ns_K)     # passes through (Ns_K[1],   err_K[1])\n",
    "\n",
    "# --------------------- β error plot ---------------------------\n",
    "p_beta = plot(sample_sizes, err_beta;\n",
    "    lw      = 2,\n",
    "    marker  = :o,\n",
    "    xscale  = :log2,\n",
    "    yscale  = :log2,\n",
    "    palette = :RdBu_4,\n",
    "    legend  = false)\n",
    "\n",
    "plot!(p_beta, sample_sizes, ref_beta;\n",
    "    lw       = 1.5,\n",
    "    ls       = :dash,\n",
    "    color    = :black)            # 1/√N guide\n",
    "\n",
    "savefig(p_beta, \"beta_errors.pdf\")\n",
    "display(p_beta)\n",
    "\n",
    "# --------------------- K error plot ---------------------------\n",
    "p_K = plot(sample_sizes, err_K;\n",
    "    lw      = 2,\n",
    "    marker  = :o,\n",
    "    xscale  = :log10,\n",
    "    yscale  = :log10,\n",
    "    xlabel  = \"Number of samples\",\n",
    "    ylabel  = \"Absolute error\",\n",
    "    title   = \"K Parameter Estimation Error vs. Sample Size\",\n",
    "    color   = my_blue,\n",
    "    legend  = false)\n",
    "\n",
    "savefig(p_K, \"K_errors.pdf\")\n",
    "display(p_K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implement an RG scheme here - we use a mix of Kadanoff's RG and mapping gauge-links to gauge-links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    coarse_grain_overlapping(sigma, U1, U2; block_size=3)\n",
    "\n",
    "Perform an overlapping block coarse–graining transformation on the lattice.\n",
    "Each block is of size block_size × block_size (default 3×3) and is defined \n",
    "for every starting position in the original lattice. The new (coarse–grained)\n",
    "lattice has size (L - block_size + 1) × (L - block_size + 1).\n",
    "\n",
    "For each block starting at (i, j):\n",
    "  - The coarse–grained horizontal link is the product of the horizontal links\n",
    "    along the top row of the block:\n",
    "      U1_new(i,j) = ∏ₖ U1(i, j+k-1), k = 1,...,block_size.\n",
    "  - The coarse–grained vertical link is the product of the vertical links along\n",
    "    the left column of the block:\n",
    "      U2_new(i,j) = ∏ₖ U2(i+k-1, j), k = 1,...,block_size.\n",
    "  - The coarse–grained spin is the product of the spins in the left column of the block:\n",
    "      sigma_new(i,j) = ∏ₖ sigma(i+k-1, j), k = 1,...,block_size.\n",
    "\n",
    "Returns the coarse–grained configuration (sigma_new, U1_new, U2_new).\n",
    "\"\"\"\n",
    "function coarse_grain_overlapping(sigma, U1, U2; block_size=2)\n",
    "    L = size(sigma, 1)\n",
    "    L_new = div(L + 1,2)  # new lattice size (overlapping blocks)\n",
    "    \n",
    "    sigma_new = Array{Int}(undef, L_new, L_new)\n",
    "    U1_new = Array{ComplexF64}(undef, L_new, L_new)\n",
    "    U2_new = Array{ComplexF64}(undef, L_new, L_new)\n",
    "    \n",
    "    for i in 1:L_new, j in 1:L_new\n",
    "        # Coarse–grained spin: product over the left column of the block.\n",
    "        s = sigma[mod1(2i-1,L),mod1(2j-1,L)] + sigma[mod1(2i,L),mod1(2j-1,L)] + sigma[mod1(2i-1,L),mod1(2j,L)] + sigma[mod1(2i,L),mod1(2j,L)]\n",
    "        if s > 0\n",
    "            sigma_new[mod1(i,L_new),mod1(j,L_new)] = 1\n",
    "        elseif s < 0\n",
    "            sigma_new[mod1(i,L_new),mod1(j,L_new)] = -1\n",
    "        else\n",
    "            sigma_new[mod1(i,L_new),mod1(j,L_new)] = rand(Bool) ? 1 : -1  # Random tie-breaker\n",
    "        end\n",
    "        \n",
    "        # Coarse–grained horizontal link: product over the top row of the block.\n",
    "    \n",
    "        U1_new[mod1(i,L_new),mod1(j,L_new)] = U1[mod1(2i-1,L),mod1(2j-1,L)]*U1[mod1(2i-1,L),mod1(2j,L)]\n",
    "        \n",
    "        # Coarse–grained vertical link: product over the left column of the block.\n",
    "        U2_new[mod1(i,L_new),mod1(j,L_new)] = U2[mod1(2i-1,L),mod1(2j-1,L)]*U2[mod1(2i,L),mod1(2j-1,L)]\n",
    "    end\n",
    "    return sigma_new, U1_new, U2_new\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now implement a full RG procedure!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, ensure you have these wrappers that accept a vector of samples:\n",
    "function neg_total_log_pseudolikelihood(samples::Vector{Tuple{Matrix{Int}, Matrix{ComplexF64}, Matrix{ComplexF64}}}, beta::Float64)\n",
    "    total_lp = 0.0\n",
    "    for (sigma, U1, U2) in samples\n",
    "        total_lp += log_pseudolikelihood_sample(beta, sigma, U1, U2)\n",
    "    end\n",
    "    return -total_lp  # negative because we maximize the log pseudolikelihood\n",
    "end\n",
    "\n",
    "function objective_K(samples::Vector{Tuple{Matrix{Int}, Matrix{ComplexF64}, Matrix{ComplexF64}}}, K::Float64, beta::Float64)\n",
    "    total_score = 0.0\n",
    "    for (sigma, U1, U2) in samples\n",
    "        total_score += hyvarinen_score_gauge(sigma, U1, U2, K, beta)\n",
    "    end\n",
    "    return total_score / length(samples)\n",
    "end\n",
    "\n",
    "# Then update your RG implementation:\n",
    "function RG_implementation(samples, rg_steps)\n",
    "    samples_init = samples\n",
    "    betas = [beta_true]\n",
    "    Ks = [K_true]\n",
    "    for i in 1:rg_steps\n",
    "        # Coarse grain the current samples\n",
    "        new_samples = [coarse_grain_overlapping(sigma, U1, U2; block_size=2) for (sigma, U1, U2) in samples_init]\n",
    "        # Estimate beta using the coarse–grained samples\n",
    "        result_beta = optimize(b -> neg_total_log_pseudolikelihood(new_samples, b), -10.0, 12.0)\n",
    "        beta_est = Optim.minimizer(result_beta)\n",
    "        # Estimate K using the coarse–grained samples and estimated beta\n",
    "        result_K = optimize(K -> objective_K(new_samples, K, beta_est), 0.0, 10.0)\n",
    "        K_est = Optim.minimizer(result_K)\n",
    "        push!(betas, beta_est)\n",
    "        push!(Ks, K_est)\n",
    "        samples_init = new_samples\n",
    "    end\n",
    "    return betas, Ks\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to learn complexity of $\\beta$ - the number of samples needed to have mean absolute errors under a certain value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using StatsBase, Plots, Random, Statistics, Optim\n",
    "\n",
    "# -----------------------------\n",
    "# Parameters for the Simulation and Complexity Study\n",
    "# -----------------------------\n",
    "\n",
    "# Simulation parameters (for the gauge model)\n",
    "L = 4                         # Lattice size (L x L)\n",
    "K_true = 1.2                   # Fixed gauge coupling (example value)\n",
    "beta_values = 1.0:0.05:2.5        # Range of \"true\" β values to test\n",
    "n_thermal = 100                # Number of sweeps for thermalization\n",
    "sweeps_between = 10            # Number of full sweeps between samples\n",
    "\n",
    "# Complexity study parameters for estimating β via pseudolikelihood\n",
    "trial_count = 50               # Number of independent trials per β at a fixed sample count\n",
    "initial_sample_count = 200     # Initial number of samples (per trial)\n",
    "max_samples = 25000            # Maximum allowed number of samples per trial\n",
    "target_error = 0.01            # Target standard error for estimated β across trials\n",
    "increase_factor = 1.1          # Multiplicative factor for sample size if error is too high\n",
    "\n",
    "# Container for recording required sample counts for each β\n",
    "samples_required = Float64[]\n",
    "\n",
    "# -----------------------------\n",
    "# Complexity Study Loop\n",
    "# -----------------------------\n",
    "for beta in beta_values\n",
    "    println(\"Testing true β = $beta\")\n",
    "    current_sample_count = initial_sample_count\n",
    "    converged = false\n",
    "\n",
    "    while !converged && current_sample_count <= max_samples\n",
    "        trial_beta_estimates = Float64[]\n",
    "        \n",
    "        # Run a number of independent trials at the current sample count.\n",
    "        for trial in 1:trial_count\n",
    "            println(\"  Trial $trial with n_samples = $current_sample_count\")\n",
    "            # Generate samples from the model (replace with your actual function).\n",
    "            # This returns a tuple (samples, energies).\n",
    "            samples, energies = generate_samples(L, K_true, beta, n_thermal, current_sample_count, sweeps_between)\n",
    "            \n",
    "            # Estimate β using your pseudolikelihood function.\n",
    "            # The optimizer finds b in [0.0, 2.0] minimizing neg_total_log_pseudolikelihood.\n",
    "            result_beta = optimize(b -> neg_total_log_pseudolikelihood(b,samples), 0.0, 2.0)\n",
    "            beta_est = Optim.minimizer(result_beta)\n",
    "            push!(trial_beta_estimates, beta_est)\n",
    "            \n",
    "            println(\"    Estimated β = $(beta_est)\")\n",
    "        end\n",
    "        \n",
    "        # Compute the standard error of the β estimates from the trials.\n",
    "        sem_beta = std(trial_beta_estimates) / sqrt(trial_count)\n",
    "        println(\"For true β = $beta with n_samples = $current_sample_count, SEM(β) = $sem_beta\")\n",
    "        \n",
    "        # Check if the standard error is below threshold.\n",
    "        if sem_beta <= target_error\n",
    "            converged = true\n",
    "            println(\"Converged for true β = $beta with n_samples = $current_sample_count\")\n",
    "            push!(samples_required, current_sample_count)\n",
    "        else\n",
    "            current_sample_count = round(Int, current_sample_count * increase_factor)\n",
    "            println(\"Increasing sample count to $current_sample_count for true β = $beta\")\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    # If we never achieved the target error, record NaN.\n",
    "    if !converged\n",
    "        println(\"Did not converge for true β = $beta within maximum samples.\")\n",
    "        push!(samples_required, NaN)\n",
    "    end\n",
    "end\n",
    "\n",
    "# -----------------------------\n",
    "# Plotting: Beta vs Required Sample Size\n",
    "# -----------------------------\n",
    "plot(beta_values, samples_required, marker=:circle, lw=2,\n",
    "     xlabel=\"True β\", ylabel=\"Required Sample Size\",\n",
    "     title=\"Complexity: Required Sample Size vs True β\\n(Target SEM ≤ $(target_error))\",\n",
    "     legend=false)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for measuring complexity of $K$ values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using StatsBase, Plots, Random, Statistics, Optim\n",
    "\n",
    "# --- Helper function to aggregate over samples, if needed ---\n",
    "# (Assuming objective_K(sample, K, sK) is defined to return a real number from one sample.)\n",
    "function total_objective_K(samples::Vector{T}, K::Float64, sK::Float64) where T\n",
    "    total = 0.0\n",
    "    for sample in samples\n",
    "        total += objective_K(sample, K, sK)\n",
    "    end\n",
    "    return total / length(samples)\n",
    "end\n",
    "\n",
    "# -----------------------------\n",
    "# Parameters for the Simulation and Complexity Study (for K)\n",
    "# -----------------------------\n",
    "L = 4                         # Lattice size (L x L)\n",
    "beta_fixed = 1.25             # Fixed beta value used in objective_K (this is sK)\n",
    "K_values = 0.5:0.1:2.5         # Range of \"true\" K values to test\n",
    "n_thermal = 100               # Number of sweeps for thermalization\n",
    "sweeps_between = 10           # Number of full sweeps between samples\n",
    "\n",
    "# Complexity study parameters for estimating K via Hyvärinen score\n",
    "trial_count = 50              # Number of independent trials per K value (for confidence interval)\n",
    "initial_sample_count = 200    # Initial number of samples (per trial)\n",
    "max_samples = 25000           # Maximum allowed number of samples per trial\n",
    "target_error = 0.01           # Target 95% CI half-width for estimated K (i.e. we require: 1.96 * SEM ≤ target_error)\n",
    "increase_factor = 1.2         # Multiplicative factor for increasing sample count\n",
    "\n",
    "# Container to record the required sample count for each true K value.\n",
    "samples_required_K = Float64[]\n",
    "\n",
    "# -----------------------------\n",
    "# Complexity Study Loop for K\n",
    "# -----------------------------\n",
    "for K_true in K_values\n",
    "    println(\"Testing true K = $K_true\")\n",
    "    current_sample_count = initial_sample_count\n",
    "    converged = false\n",
    "\n",
    "    while current_sample_count ≤ max_samples && !converged\n",
    "        trial_K_estimates = Float64[]\n",
    "        \n",
    "        # Run trial_count independent trials at the current sample count.\n",
    "        for trial in 1:trial_count\n",
    "            println(\"  Trial $trial with n_samples = $current_sample_count\")\n",
    "            # Generate samples from the model.\n",
    "            # Assume generate_samples(L, K, beta, n_thermal, n_samples, sweeps_between)\n",
    "            # returns a vector of sample configurations and associated energies.\n",
    "            samples, energies = generate_samples(L, K_true, beta_fixed, n_thermal, round(Int, current_sample_count), sweeps_between)\n",
    "            \n",
    "            # Estimate K using your pseudolikelihood-based objective.\n",
    "            # (Using a simple univariate optimization over K in, say, [0, 10].)\n",
    "            result_K = optimize(K -> objective_K(samples, K, beta_fixed), 0.0, 10.0)\n",
    "            K_est = Optim.minimizer(result_K)\n",
    "            push!(trial_K_estimates, K_est)\n",
    "            println(\"    Estimated K = $(K_est)\")\n",
    "        end\n",
    "        \n",
    "        # Compute the standard error (SEM) and the 95% CI half-width.\n",
    "        sem_K = std(trial_K_estimates) / sqrt(trial_count)\n",
    "        ci_half_width = 1.96 * sem_K\n",
    "        println(\"For true K = $K_true with n_samples = $(current_sample_count), 95% CI half-width = $(ci_half_width)\")\n",
    "        \n",
    "        if ci_half_width ≤ target_error\n",
    "            println(\"  ✓ Converged for true K = $K_true with n_samples = $(current_sample_count)\")\n",
    "            push!(samples_required_K, round(Int, current_sample_count))\n",
    "            converged = true\n",
    "        else\n",
    "            current_sample_count = round(Int, current_sample_count * increase_factor)\n",
    "            println(\"Increasing sample count to $(current_sample_count) for true K = $K_true\")\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # If we never reached the target CI half-width, record NaN.\n",
    "    if !converged\n",
    "        println(\"  ✗ True K = $K_true: Did not reach target CI half-width\")\n",
    "        push!(samples_required_K, NaN)\n",
    "    end\n",
    "end\n",
    "\n",
    "# -----------------------------\n",
    "# Plotting: True K vs. Required Sample Size\n",
    "# -----------------------------\n",
    "p = plot(K_values, samples_required_K, marker=:circle, lw=2,\n",
    "         xlabel=\"True K\", ylabel=\"Required Sample Size\",\n",
    "         title=\"Complexity: Required Sample Size vs True K\\n(95% CI half-width ≤ $(target_error))\",\n",
    "         legend=false)\n",
    "display(p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now a code to run a full RG trajectory!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function run_RG_trajectory(K0, β0; L=16, n_samples=10_000,\n",
    "                           n_thermal=200, sweeps_between=10,\n",
    "                           rg_steps=3)\n",
    "\n",
    "    # ---- generate Monte-Carlo data at (K0, β0) ----\n",
    "    samples, _ = generate_samples(L, K0, β0,\n",
    "                                  n_thermal, n_samples, sweeps_between)\n",
    "\n",
    "    # make K₀, β₀ visible inside RG_implementation\n",
    "    global K_true  = K0\n",
    "    global beta_true = β0\n",
    "\n",
    "    βs, Ks = RG_implementation(samples, rg_steps)\n",
    "    return βs, Ks\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_fixed   = 0.1\n",
    "β0_list   = 1.0:0.2:2.4\n",
    "L = 8\n",
    "rg_steps=1\n",
    "n_samples=10_000\n",
    "n_thermal = 2000\n",
    "sweeps_between=8\n",
    "\n",
    "for (idx, β0) in enumerate(β0_list)\n",
    "    βs, Ks = run_RG_trajectory(K_fixed, β0;\n",
    "                                L=L, n_samples=n_samples, rg_steps=rg_steps,\n",
    "                                n_thermal=n_thermal, sweeps_between=sweeps_between)\n",
    "    println(\"Initial β₀ = $β0: Final (β, K) = ($(βs[end]), $(Ks[end]))\")\n",
    "end\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.4",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
